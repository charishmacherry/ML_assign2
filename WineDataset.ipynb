{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WineDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLavD31sIL3h",
        "outputId": "1fb90769-ea10-4065-8f0e-2dfdeeab12f4"
      },
      "source": [
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "wine_dataset = datasets.load_wine()\n",
        "df = pd.DataFrame(wine_dataset.data, columns=wine_dataset.feature_names)\n",
        "df['target'] = wine_dataset.target\n",
        "df.head()\n",
        "\n",
        "X, y = wine_dataset.data, wine_dataset.target\n",
        "\n",
        "# spliting data to train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3,stratify=y, random_state=42)\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((124, 13), (124,), (54, 13), (54,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAF6awTRXsXk"
      },
      "source": [
        "def get_params(X_train, y_train): \n",
        "    num_examples, num_features = X_train.shape\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    return num_examples, num_features, num_classes"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c29z5-ZX1rf",
        "outputId": "599122d6-8914-46ca-c751-76215b2abc53"
      },
      "source": [
        "# testing utility function\n",
        "num_examples, num_features, num_classes = get_params(X_train, y_train)\n",
        "print(num_examples, num_features, num_classes)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "124 13 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGsqF5SqX2zr"
      },
      "source": [
        "def get_stats_by_class(X_train, y_train, num_examples=num_examples, num_classes=num_classes): \n",
        "    \"\"\"\n",
        "    Get stats of dataset by the class\n",
        "    \"\"\"\n",
        "    # dictionaries to store stats\n",
        "    class_mean = {}\n",
        "    class_var = {} \n",
        "    class_prior = {} \n",
        "    \n",
        "    # loop through each class and get mean, variance and prior by class\n",
        "    for cls in range(num_classes): \n",
        "        X_cls = X_train[y_train == cls]\n",
        "        class_mean[str(cls)] = np.mean(X_cls, axis=0)\n",
        "        class_var[str(cls)] = np.var(X_cls, axis=0)\n",
        "        class_prior[str(cls)] = X_cls.shape[0] / num_examples\n",
        "    return class_mean, class_var, class_prior"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhKtaEPrX71b"
      },
      "source": [
        "def gaussian_density_function(X, mean, std, num_examples=num_examples, num_features=num_features, eps=1e-6): \n",
        "    num_exambles, num_features = X_train.shape\n",
        "    const = -num_features/2 * np.log(2*np.pi) - 0.5 * np.sum(np.log(std + eps))\n",
        "    probs = 0.5 * np.sum(np.power(X - mean, 2)/(std + eps), 1)\n",
        "    return const - probs"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hytzHtvYBSG"
      },
      "source": [
        "def class_probabilities(X, class_mean, class_var, class_prior, num_classes=num_classes):\n",
        "    \"\"\"\n",
        "    calculate the probability of each class given the data\n",
        "    \"\"\"\n",
        "    num_examples = X.shape[0]\n",
        "    probs = np.zeros((num_examples, num_classes))\n",
        "\n",
        "    for cls in range(num_classes): \n",
        "        prior = class_prior[str(cls)]\n",
        "        probs_cls = gaussian_density_function(X, class_mean[str(cls)], class_var[str(cls)])\n",
        "        probs[:, cls] = probs_cls + np.log(prior)\n",
        "    return probs"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jva9xfcUYGMh"
      },
      "source": [
        "def predict(X_test, X_train, y_train): \n",
        "    num_examples, num_features, num_classes = get_params(X_test, y_train)\n",
        "    class_mean, class_std, class_prior = get_stats_by_class(X_train, y_train)\n",
        "    probs = class_probabilities(X_test, class_mean, class_std, class_prior)\n",
        "    return np.argmax(probs, 1)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLjrYZpkd4bj"
      },
      "source": [
        "#separate by class\n",
        "def seperate_by_class(dataset):\n",
        "  zero = dataset[dataset['target'] == 0]\n",
        "  one = dataset[dataset['target'] == 1]\n",
        "  two = dataset[dataset['target'] == 2]\n",
        "  return zero, one, two"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiUyw55LadK8"
      },
      "source": [
        "def accuracy(test_set, my_preds):\n",
        "    correct = 0\n",
        "    actual = test_set\n",
        "    for x, y in zip(actual, my_preds):\n",
        "        if x == y:\n",
        "            correct += 1\n",
        "    return correct / float(len(test_set))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FykhDssFpZJv"
      },
      "source": [
        "Que 2A)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ6jBpeSpYkC",
        "outputId": "3ca7369d-5c40-4643-bfee-126cec7d673a"
      },
      "source": [
        "# scikit learn implementation \n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "sklearn_preds = nb.predict(X_test)\n",
        "\n",
        "print(f\"sklearn accuracy:{accuracy_score(y_test, sklearn_preds)}\")\n",
        "print(f\"predictions: {sklearn_preds}\")\n",
        "\n",
        "# Mean, Variance, class prior \n",
        "cm, var, cp = get_stats_by_class(X_train, y_train)\n",
        "print(f\"mean: {cm}\\n\\nvariance: {var}\\n\\npriors: {cp}\")\n",
        "\n",
        "my_preds = predict(X_test, X_train, y_train)\n",
        "sklearn_preds == my_preds\n",
        "\n",
        "probs = class_probabilities(X_train, cm, var, cp)\n",
        "\n",
        "print('Accuracy')\n",
        "print(accuracy(y_test, my_preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, my_preds)\n",
        "print(cm)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sklearn accuracy:1.0\n",
            "predictions: [0 1 0 0 0 0 2 1 1 2 1 1 2 1 0 2 1 0 2 2 1 2 2 2 1 2 0 1 0 1 0 1 2 1 1 2 1\n",
            " 1 1 0 2 0 0 0 0 1 1 0 2 0 1 1 2 0]\n",
            "mean: {'0': array([1.37304878e+01, 1.94707317e+00, 2.44975610e+00, 1.71024390e+01,\n",
            "       1.06634146e+02, 2.82853659e+00, 2.94024390e+00, 3.01707317e-01,\n",
            "       1.85121951e+00, 5.56780488e+00, 1.05097561e+00, 3.08853659e+00,\n",
            "       1.11280488e+03]), '1': array([1.22424e+01, 1.96260e+00, 2.23280e+00, 2.05240e+01, 9.51400e+01,\n",
            "       2.25360e+00, 2.04680e+00, 3.50800e-01, 1.71220e+00, 2.96080e+00,\n",
            "       1.05892e+00, 2.80220e+00, 5.31260e+02]), '2': array([1.30745455e+01, 3.20090909e+00, 2.45424242e+00, 2.15606061e+01,\n",
            "       9.92727273e+01, 1.68757576e+00, 7.87575758e-01, 4.46363636e-01,\n",
            "       1.13878788e+00, 7.36272724e+00, 6.73030303e-01, 1.69060606e+00,\n",
            "       6.24393939e+02])}\n",
            "\n",
            "variance: {'0': array([2.02950982e-01, 3.95762165e-01, 6.05975015e-02, 7.29535990e+00,\n",
            "       1.16280785e+02, 1.14880785e-01, 1.37626770e-01, 5.39464604e-03,\n",
            "       1.46386318e-01, 1.48304152e+00, 1.26624628e-02, 1.08866151e-01,\n",
            "       3.97256692e+04]), '1': array([2.70046240e-01, 1.10783524e+00, 7.88841600e-02, 1.05854240e+01,\n",
            "       3.47600400e+02, 2.97211040e-01, 3.66681760e-01, 1.23193600e-02,\n",
            "       3.59241160e-01, 7.50035360e-01, 3.96851536e-02, 2.28521160e-01,\n",
            "       2.57562324e+04]), '2': array([2.61655096e-01, 8.79135537e-01, 3.18062443e-02, 4.78420569e+00,\n",
            "       1.02865014e+02, 1.47394123e-01, 1.02339578e-01, 1.45322314e-02,\n",
            "       2.12774288e-01, 5.87018938e+00, 1.39726354e-02, 8.49269054e-02,\n",
            "       1.35632691e+04])}\n",
            "\n",
            "priors: {'0': 0.33064516129032256, '1': 0.4032258064516129, '2': 0.2661290322580645}\n",
            "Accuracy\n",
            "1.0\n",
            "[[18  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5MGA1buqgxH"
      },
      "source": [
        "Que 2B) i)40-40-20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_uYKot7qn2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024455d1-2a81-4d8b-a2cd-f5ee4e744d1b"
      },
      "source": [
        "def get_stats_by_class_ratio(X_train, y_train, num_examples=num_examples, num_classes=num_classes): \n",
        "    # dictionaries to store stats\n",
        "    mean = {}\n",
        "    variance = {} \n",
        "    prior = {'0':0.40,'1':0.40,'2':0.20} \n",
        "    \n",
        "    # loop through each class and get mean, variance and prior by class\n",
        "    for cls in range(num_classes): \n",
        "        X_cls = X_train[y_train == cls]\n",
        "        mean[str(cls)] = np.mean(X_cls, axis=0)\n",
        "        variance[str(cls)] = np.var(X_cls, axis=0)\n",
        "        prior[str(cls)] = X_cls.shape[0] / num_examples\n",
        "    return mean, variance, prior\n",
        "\n",
        "# Mean, Variance, class prior \n",
        "cm, var, cp = get_stats_by_class_ratio(X_train, y_train)\n",
        "print(f\"mean: {cm}\\n\\nvariance: {var}\\n\\npriors: {cp}\")\n",
        "\n",
        "my_preds = predict(X_test, X_train, y_train)\n",
        "sklearn_preds == my_preds\n",
        "\n",
        "probs = class_probabilities(X_train, cm, var, cp)\n",
        "\n",
        "print('Accuracy')\n",
        "print(accuracy(y_test, my_preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, my_preds)\n",
        "print(cm)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: {'0': array([1.37304878e+01, 1.94707317e+00, 2.44975610e+00, 1.71024390e+01,\n",
            "       1.06634146e+02, 2.82853659e+00, 2.94024390e+00, 3.01707317e-01,\n",
            "       1.85121951e+00, 5.56780488e+00, 1.05097561e+00, 3.08853659e+00,\n",
            "       1.11280488e+03]), '1': array([1.22424e+01, 1.96260e+00, 2.23280e+00, 2.05240e+01, 9.51400e+01,\n",
            "       2.25360e+00, 2.04680e+00, 3.50800e-01, 1.71220e+00, 2.96080e+00,\n",
            "       1.05892e+00, 2.80220e+00, 5.31260e+02]), '2': array([1.30745455e+01, 3.20090909e+00, 2.45424242e+00, 2.15606061e+01,\n",
            "       9.92727273e+01, 1.68757576e+00, 7.87575758e-01, 4.46363636e-01,\n",
            "       1.13878788e+00, 7.36272724e+00, 6.73030303e-01, 1.69060606e+00,\n",
            "       6.24393939e+02])}\n",
            "\n",
            "variance: {'0': array([2.02950982e-01, 3.95762165e-01, 6.05975015e-02, 7.29535990e+00,\n",
            "       1.16280785e+02, 1.14880785e-01, 1.37626770e-01, 5.39464604e-03,\n",
            "       1.46386318e-01, 1.48304152e+00, 1.26624628e-02, 1.08866151e-01,\n",
            "       3.97256692e+04]), '1': array([2.70046240e-01, 1.10783524e+00, 7.88841600e-02, 1.05854240e+01,\n",
            "       3.47600400e+02, 2.97211040e-01, 3.66681760e-01, 1.23193600e-02,\n",
            "       3.59241160e-01, 7.50035360e-01, 3.96851536e-02, 2.28521160e-01,\n",
            "       2.57562324e+04]), '2': array([2.61655096e-01, 8.79135537e-01, 3.18062443e-02, 4.78420569e+00,\n",
            "       1.02865014e+02, 1.47394123e-01, 1.02339578e-01, 1.45322314e-02,\n",
            "       2.12774288e-01, 5.87018938e+00, 1.39726354e-02, 8.49269054e-02,\n",
            "       1.35632691e+04])}\n",
            "\n",
            "priors: {'0': 0.33064516129032256, '1': 0.4032258064516129, '2': 0.2661290322580645}\n",
            "Accuracy\n",
            "1.0\n",
            "[[18  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8smgF36I5Eol"
      },
      "source": [
        "2B) 80-10-10\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSAJkow65HY3",
        "outputId": "7c673a6d-5bbf-46f4-f389-c3e83c6232a5"
      },
      "source": [
        "def get_stats_by_class_ratio(X_train, y_train, num_examples=num_examples, num_classes=num_classes): \n",
        "    # dictionaries to store stats\n",
        "    mean = {}\n",
        "    variance = {} \n",
        "    prior = {'0':0.80,'1':0.10,'2':0.10} \n",
        "    \n",
        "    # loop through each class and get mean, variance and prior by class\n",
        "    for cls in range(num_classes): \n",
        "        X_cls = X_train[y_train == cls]\n",
        "        mean[str(cls)] = np.mean(X_cls, axis=0)\n",
        "        variance[str(cls)] = np.var(X_cls, axis=0)\n",
        "        prior[str(cls)] = X_cls.shape[0] / num_examples\n",
        "    return mean, variance, prior\n",
        "\n",
        "# Mean, Variance, class prior \n",
        "cm, var, cp = get_stats_by_class_ratio(X_train, y_train)\n",
        "print(f\"mean: {cm}\\n\\nvariance: {var}\\n\\npriors: {cp}\")\n",
        "\n",
        "my_preds = predict(X_test, X_train, y_train)\n",
        "sklearn_preds == my_preds\n",
        "\n",
        "probs = class_probabilities(X_train, cm, var, cp)\n",
        "\n",
        "print('Accuracy')\n",
        "print(accuracy(y_test, my_preds))\n",
        "\n",
        "cm = confusion_matrix(y_test, my_preds)\n",
        "print(cm)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: {'0': array([1.37304878e+01, 1.94707317e+00, 2.44975610e+00, 1.71024390e+01,\n",
            "       1.06634146e+02, 2.82853659e+00, 2.94024390e+00, 3.01707317e-01,\n",
            "       1.85121951e+00, 5.56780488e+00, 1.05097561e+00, 3.08853659e+00,\n",
            "       1.11280488e+03]), '1': array([1.22424e+01, 1.96260e+00, 2.23280e+00, 2.05240e+01, 9.51400e+01,\n",
            "       2.25360e+00, 2.04680e+00, 3.50800e-01, 1.71220e+00, 2.96080e+00,\n",
            "       1.05892e+00, 2.80220e+00, 5.31260e+02]), '2': array([1.30745455e+01, 3.20090909e+00, 2.45424242e+00, 2.15606061e+01,\n",
            "       9.92727273e+01, 1.68757576e+00, 7.87575758e-01, 4.46363636e-01,\n",
            "       1.13878788e+00, 7.36272724e+00, 6.73030303e-01, 1.69060606e+00,\n",
            "       6.24393939e+02])}\n",
            "\n",
            "variance: {'0': array([2.02950982e-01, 3.95762165e-01, 6.05975015e-02, 7.29535990e+00,\n",
            "       1.16280785e+02, 1.14880785e-01, 1.37626770e-01, 5.39464604e-03,\n",
            "       1.46386318e-01, 1.48304152e+00, 1.26624628e-02, 1.08866151e-01,\n",
            "       3.97256692e+04]), '1': array([2.70046240e-01, 1.10783524e+00, 7.88841600e-02, 1.05854240e+01,\n",
            "       3.47600400e+02, 2.97211040e-01, 3.66681760e-01, 1.23193600e-02,\n",
            "       3.59241160e-01, 7.50035360e-01, 3.96851536e-02, 2.28521160e-01,\n",
            "       2.57562324e+04]), '2': array([2.61655096e-01, 8.79135537e-01, 3.18062443e-02, 4.78420569e+00,\n",
            "       1.02865014e+02, 1.47394123e-01, 1.02339578e-01, 1.45322314e-02,\n",
            "       2.12774288e-01, 5.87018938e+00, 1.39726354e-02, 8.49269054e-02,\n",
            "       1.35632691e+04])}\n",
            "\n",
            "priors: {'0': 0.33064516129032256, '1': 0.4032258064516129, '2': 0.2661290322580645}\n",
            "Accuracy\n",
            "1.0\n",
            "[[18  0  0]\n",
            " [ 0 21  0]\n",
            " [ 0  0 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}